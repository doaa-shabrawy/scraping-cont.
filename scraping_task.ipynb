{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00 US Dollar =50.860003 Egyptian Pounds\n",
      "3.0 US Dollar = 152.580009 Egyptian Pounds\n"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "res = requests.get(\"https://www.xe.com/currencyconverter/convert/?Amount=1&From=USD&To=EGP\") #scraping the data\n",
    "soup = BeautifulSoup(res.text,\"html.parser\")#parsing the data\n",
    "div_tag = soup.find(\"div\",attrs= {\"class\":\"[grid-area:conversion]\"})\n",
    "usd_egp = div_tag.find(\"div\").find_all(\"p\")[0].text + div_tag.find(\"div\").find_all(\"p\")[1].text #scraping USD TO EGP exchange\n",
    "print(usd_egp)\n",
    "#the S.W \n",
    "egp = float(div_tag.find(\"div\").find_all(\"p\")[1].text.split(\" \")[0])\n",
    "user_input = float(input(\"please enter the amount in dollars\"))\n",
    "result = user_input * egp\n",
    "print(f\"{user_input} US Dollar = {result} Egyptian Pounds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Book Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>Â£51.77</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>Â£53.74</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Soumission</td>\n",
       "      <td>Â£50.10</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>Â£54.23</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>Â£22.65</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
       "      <td>Â£33.34</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
       "      <td>Â£17.93</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "      <td>Â£22.60</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>Â£52.15</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Starving Hearts (Triangular Trade Trilogy, #1)</td>\n",
       "      <td>Â£13.99</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>Â£20.66</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>Â£17.46</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Scott Pilgrim's Precious Little Life (Scott Pi...</td>\n",
       "      <td>Â£52.29</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Rip it Up and Start Again</td>\n",
       "      <td>Â£35.02</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Our Band Could Be Your Life: Scenes from the A...</td>\n",
       "      <td>Â£57.25</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Olio</td>\n",
       "      <td>Â£23.88</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Mesaerion: The Best Science Fiction Stories 18...</td>\n",
       "      <td>Â£37.59</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>Â£51.33</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>Â£45.17</td>\n",
       "      <td>Two</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                          Book Name Book Price  Rating\n",
       "0    1                               A Light in the Attic    Â£51.77   Three\n",
       "1    2                                 Tipping the Velvet    Â£53.74     One\n",
       "2    3                                         Soumission    Â£50.10     One\n",
       "3    4                                      Sharp Objects    Â£47.82    Four\n",
       "4    5              Sapiens: A Brief History of Humankind    Â£54.23    Five\n",
       "5    6                                    The Requiem Red    Â£22.65     One\n",
       "6    7  The Dirty Little Secrets of Getting Your Dream...    Â£33.34    Four\n",
       "7    8  The Coming Woman: A Novel Based on the Life of...    Â£17.93   Three\n",
       "8    9  The Boys in the Boat: Nine Americans and Their...    Â£22.60    Four\n",
       "9   10                                    The Black Maria    Â£52.15     One\n",
       "10  11     Starving Hearts (Triangular Trade Trilogy, #1)    Â£13.99     Two\n",
       "11  12                              Shakespeare's Sonnets    Â£20.66    Four\n",
       "12  13                                        Set Me Free    Â£17.46    Five\n",
       "13  14  Scott Pilgrim's Precious Little Life (Scott Pi...    Â£52.29    Five\n",
       "14  15                          Rip it Up and Start Again    Â£35.02    Five\n",
       "15  16  Our Band Could Be Your Life: Scenes from the A...    Â£57.25   Three\n",
       "16  17                                               Olio    Â£23.88     One\n",
       "17  18  Mesaerion: The Best Science Fiction Stories 18...    Â£37.59     One\n",
       "18  19                       Libertarianism for Beginners    Â£51.33     Two\n",
       "19  20                            It's Only the Himalayas    Â£45.17     Two"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task 3 for one page\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "res = requests.get(\"https://books.toscrape.com/\")\n",
    "soup = BeautifulSoup(res.text,\"html.parser\")\n",
    "article_tags = soup.find_all(\"article\")\n",
    "\n",
    "#name = soup.find_all(\"article\")[0].find(\"h3\").text\n",
    "'''\n",
    "book_link = \"https://books.toscrape.com/\"+ soup.find_all(\"article\")[0].find(\"h3\").find(\"a\").attrs[\"href\"]\n",
    "book_res = requests.get(book_link)\n",
    "book_res\n",
    "book_soup = BeautifulSoup(book_res.text,\"html.parser\")\n",
    "book_name = book_soup.find(\"div\",{\"class\":\"col-sm-6 product_main\"}).find(\"h1\").text\n",
    "book_price = soup.find_all(\"article\")[0].find(\"div\",{\"class\":\"product_price\"}).find(\"p\").text\n",
    "rating = soup.find_all(\"article\")[0].find(\"p\").get(\"class\")[1]'''\n",
    "\n",
    "name_list = []\n",
    "price_list = []\n",
    "rating_list = []\n",
    "\n",
    "with open (\"book.csv\", mode = \"w\", encoding=\"utf-8\") as fd :\n",
    "    fd.write(\"id,Book Name,Book Price, Rating\\n\")\n",
    "    for i in range(len(article_tags)):\n",
    "\n",
    "        book_link = \"https://books.toscrape.com/\"+ soup.find_all(\"article\")[i].find(\"h3\").find(\"a\").attrs[\"href\"]\n",
    "        book_res = requests.get(book_link)\n",
    "        book_soup = BeautifulSoup(book_res.text,\"html.parser\")\n",
    "        name_list.append(book_soup.find(\"div\",{\"class\":\"col-sm-6 product_main\"}).find(\"h1\").text)\n",
    "        price_list.append(soup.find_all(\"article\")[i].find(\"div\",{\"class\":\"product_price\"}).find(\"p\").text)\n",
    "        rating_list.append(soup.find_all(\"article\")[i].find(\"p\").get(\"class\")[1])\n",
    "        fd.write(f\"{i+1},\\\"{name_list[i]}\\\",\\\"{price_list[i]}\\\",\\\"{rating_list[i]}\\\"\\n\")\n",
    "\n",
    "books_df = pd.read_csv(\"book.csv\")  \n",
    "books_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Book Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Light in the ...</td>\n",
       "      <td>Â£51.77</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>Â£53.74</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Soumission</td>\n",
       "      <td>Â£50.10</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sapiens: A Brief History ...</td>\n",
       "      <td>Â£54.23</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>976</td>\n",
       "      <td>Icing (Aces Hockey #2)</td>\n",
       "      <td>Â£40.44</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>977</td>\n",
       "      <td>Hawkeye, Vol. 1: My ...</td>\n",
       "      <td>Â£45.24</td>\n",
       "      <td>Three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>978</td>\n",
       "      <td>Having the Barbarian's Baby ...</td>\n",
       "      <td>Â£34.96</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>979</td>\n",
       "      <td>Giant Days, Vol. 1 ...</td>\n",
       "      <td>Â£56.76</td>\n",
       "      <td>Four</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>980</td>\n",
       "      <td>Fruits Basket, Vol. 1 ...</td>\n",
       "      <td>Â£40.28</td>\n",
       "      <td>Five</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        Book Name Book Price  Rating\n",
       "0      1               A Light in the ...    Â£51.77   Three\n",
       "1      2               Tipping the Velvet    Â£53.74     One\n",
       "2      3                       Soumission    Â£50.10     One\n",
       "3      4                    Sharp Objects    Â£47.82    Four\n",
       "4      5     Sapiens: A Brief History ...    Â£54.23    Five\n",
       "..   ...                              ...        ...     ...\n",
       "975  976           Icing (Aces Hockey #2)    Â£40.44    Four\n",
       "976  977          Hawkeye, Vol. 1: My ...    Â£45.24   Three\n",
       "977  978  Having the Barbarian's Baby ...    Â£34.96    Four\n",
       "978  979           Giant Days, Vol. 1 ...    Â£56.76    Four\n",
       "979  980        Fruits Basket, Vol. 1 ...    Â£40.28    Five\n",
       "\n",
       "[980 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task 3 with pigination\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "conut_res = requests.get(\"https://books.toscrape.com/\")\n",
    "count_soup = BeautifulSoup(conut_res.text,\"html.parser\")\n",
    "page_count = int(count_soup.find(\"li\",attrs={\"class\":\"current\"}).text.strip(\"\\n  \\n  \\n\").split(\" \")[3])\n",
    "name_list = []\n",
    "price_list = []\n",
    "rating_list = []\n",
    "for j in range(page_count):\n",
    "    res = requests.get(f\"https://books.toscrape.com/catalogue/page-{j}.html\")  \n",
    "    soup = BeautifulSoup(res.text,\"html.parser\")  \n",
    "    soup  \n",
    "    article_tags = soup.find_all(\"article\")\n",
    "\n",
    "    for i in range(len(article_tags)):\n",
    "            name_list.append(soup.find_all(\"article\")[i].find(\"h3\").text)\n",
    "            price_list.append(soup.find_all(\"article\")[i].find(\"div\",{\"class\":\"product_price\"}).find(\"p\").text)\n",
    "            rating_list.append(soup.find_all(\"article\")[i].find(\"p\").get(\"class\")[1])\n",
    "            \n",
    "with open (\"books.csv\", mode = \"w\", encoding=\"utf-8\") as fd :\n",
    "        fd.write(\"id,Book Name,Book Price, Rating\\n\")\n",
    "        for i in range(len(price_list)):\n",
    "             fd.write(f\"{i+1},\\\"{name_list[i]}\\\",\\\"{price_list[i]}\\\",\\\"{rating_list[i]}\\\"\\n\")\n",
    "books_df = pd.read_csv(\"books.csv\")  \n",
    "books_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Capital</th>\n",
       "      <th>Poulation</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Andorra</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>84000</td>\n",
       "      <td>468.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Arab Emirates</th>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>4975593</td>\n",
       "      <td>82880.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>Kabul</td>\n",
       "      <td>29121286</td>\n",
       "      <td>647500.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Antigua and Barbuda</th>\n",
       "      <td>St. John's</td>\n",
       "      <td>86754</td>\n",
       "      <td>443.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anguilla</th>\n",
       "      <td>The Valley</td>\n",
       "      <td>13254</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yemen</th>\n",
       "      <td>Sanaa</td>\n",
       "      <td>23495361</td>\n",
       "      <td>527970.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mayotte</th>\n",
       "      <td>Mamoudzou</td>\n",
       "      <td>159042</td>\n",
       "      <td>374.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Africa</th>\n",
       "      <td>Pretoria</td>\n",
       "      <td>49000000</td>\n",
       "      <td>1219912.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zambia</th>\n",
       "      <td>Lusaka</td>\n",
       "      <td>13460305</td>\n",
       "      <td>752614.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zimbabwe</th>\n",
       "      <td>Harare</td>\n",
       "      <td>11651858</td>\n",
       "      <td>390580.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Country Name   Capital  Poulation  Area\n",
       "Andorra               Andorra la Vella     84000      468.0   NaN\n",
       "United Arab Emirates         Abu Dhabi   4975593    82880.0   NaN\n",
       "Afghanistan                      Kabul  29121286   647500.0   NaN\n",
       "Antigua and Barbuda         St. John's     86754      443.0   NaN\n",
       "Anguilla                    The Valley     13254      102.0   NaN\n",
       "...                                ...       ...        ...   ...\n",
       "Yemen                            Sanaa  23495361   527970.0   NaN\n",
       "Mayotte                      Mamoudzou    159042      374.0   NaN\n",
       "South Africa                  Pretoria  49000000  1219912.0   NaN\n",
       "Zambia                          Lusaka  13460305   752614.0   NaN\n",
       "Zimbabwe                        Harare  11651858   390580.0   NaN\n",
       "\n",
       "[250 rows x 4 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "res = requests.get(\"https://www.scrapethissite.com/pages/simple/\")\n",
    "res\n",
    "soup = BeautifulSoup(res.text,\"html.parser\")\n",
    "the_main_div = soup.find_all(\"div\",{\"class\":\"col-md-4 country\"})\n",
    "#firstly we try for the the_main_div [0]\n",
    "#the_main_div = soup.find_all(\"div\",{\"class\":\"col-md-4 country\"})[0]\n",
    "#country_name = the_main_div.find(\"h3\").text.strip(\" \").strip(\"\\n\").strip(\" \")\n",
    "#country_capital = the_main_div.find(\"span\",{\"class\":\"country-capital\"}).text\n",
    "#country_population = the_main_div.find(\"span\",{\"class\":\"country-population\"}).text\n",
    "#country_area = the_main_div.find(\"span\",{\"class\":\"country-area\"}).text\n",
    "\n",
    "name = []\n",
    "capital = []\n",
    "popualtion = []\n",
    "area = []\n",
    "with open(\"country.csv\",mode=\"w\",encoding=\"utf-8\") as fd :\n",
    "    fd.write(\"Country Name,Capital,Poulation,Area\\n\")\n",
    "\n",
    "    for i in range(len(the_main_div)):\n",
    "        the_main_div = soup.find_all(\"div\",{\"class\":\"col-md-4 country\"})[i]\n",
    "        name.append(the_main_div.find(\"h3\").text.strip(\" \").strip(\"\\n\").strip(\" \"))\n",
    "        capital.append(the_main_div.find(\"span\",{\"class\":\"country-capital\"}).text)\n",
    "        popualtion.append(the_main_div.find(\"span\",{\"class\":\"country-population\"}).text)\n",
    "        area.append(the_main_div.find(\"span\",{\"class\":\"country-area\"}).text)\n",
    "        fd.write(f\"\\\"{name[i]}\\\",\\\"{capital[i]}\\\",\\\"{popualtion[i]}\\\",\\\"{area[i]}\\\",\\n\")\n",
    "\n",
    "country_df = pd.read_csv(\"country.csv\")\n",
    "country_df    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Wins</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Win%</th>\n",
       "      <th>Goal for</th>\n",
       "      <th>Goal aganist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Boston Bruins</th>\n",
       "      <td>1990</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>0.550</td>\n",
       "      <td>299</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buffalo Sabres</th>\n",
       "      <td>1990</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>0.388</td>\n",
       "      <td>292</td>\n",
       "      <td>278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calgary Flames</th>\n",
       "      <td>1990</td>\n",
       "      <td>46</td>\n",
       "      <td>26</td>\n",
       "      <td>0.575</td>\n",
       "      <td>344</td>\n",
       "      <td>263</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago Blackhawks</th>\n",
       "      <td>1990</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>0.613</td>\n",
       "      <td>284</td>\n",
       "      <td>211</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Detroit Red Wings</th>\n",
       "      <td>1990</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>0.425</td>\n",
       "      <td>273</td>\n",
       "      <td>298</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Edmonton Oilers</th>\n",
       "      <td>1990</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>0.463</td>\n",
       "      <td>272</td>\n",
       "      <td>272</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hartford Whalers</th>\n",
       "      <td>1990</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>0.388</td>\n",
       "      <td>238</td>\n",
       "      <td>276</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles Kings</th>\n",
       "      <td>1990</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "      <td>0.575</td>\n",
       "      <td>340</td>\n",
       "      <td>254</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota North Stars</th>\n",
       "      <td>1990</td>\n",
       "      <td>27</td>\n",
       "      <td>39</td>\n",
       "      <td>0.338</td>\n",
       "      <td>256</td>\n",
       "      <td>266</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montreal Canadiens</th>\n",
       "      <td>1990</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>0.487</td>\n",
       "      <td>273</td>\n",
       "      <td>249</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey Devils</th>\n",
       "      <td>1990</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>0.400</td>\n",
       "      <td>272</td>\n",
       "      <td>264</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Islanders</th>\n",
       "      <td>1990</td>\n",
       "      <td>25</td>\n",
       "      <td>45</td>\n",
       "      <td>0.312</td>\n",
       "      <td>223</td>\n",
       "      <td>290</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Rangers</th>\n",
       "      <td>1990</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>0.450</td>\n",
       "      <td>297</td>\n",
       "      <td>265</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philadelphia Flyers</th>\n",
       "      <td>1990</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>0.412</td>\n",
       "      <td>252</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pittsburgh Penguins</th>\n",
       "      <td>1990</td>\n",
       "      <td>41</td>\n",
       "      <td>33</td>\n",
       "      <td>0.512</td>\n",
       "      <td>342</td>\n",
       "      <td>305</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quebec Nordiques</th>\n",
       "      <td>1990</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "      <td>0.200</td>\n",
       "      <td>236</td>\n",
       "      <td>354</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St. Louis Blues</th>\n",
       "      <td>1990</td>\n",
       "      <td>47</td>\n",
       "      <td>22</td>\n",
       "      <td>0.588</td>\n",
       "      <td>310</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Toronto Maple Leafs</th>\n",
       "      <td>1990</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>0.287</td>\n",
       "      <td>241</td>\n",
       "      <td>318</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vancouver Canucks</th>\n",
       "      <td>1990</td>\n",
       "      <td>28</td>\n",
       "      <td>43</td>\n",
       "      <td>0.350</td>\n",
       "      <td>243</td>\n",
       "      <td>315</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington Capitals</th>\n",
       "      <td>1990</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>0.463</td>\n",
       "      <td>258</td>\n",
       "      <td>258</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Winnipeg Jets</th>\n",
       "      <td>1990</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "      <td>0.325</td>\n",
       "      <td>260</td>\n",
       "      <td>288</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Boston Bruins</th>\n",
       "      <td>1991</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>0.450</td>\n",
       "      <td>270</td>\n",
       "      <td>275</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Buffalo Sabres</th>\n",
       "      <td>1991</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>0.388</td>\n",
       "      <td>289</td>\n",
       "      <td>299</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calgary Flames</th>\n",
       "      <td>1991</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>0.388</td>\n",
       "      <td>296</td>\n",
       "      <td>305</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chicago Blackhawks</th>\n",
       "      <td>1991</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>0.450</td>\n",
       "      <td>257</td>\n",
       "      <td>236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Team name  Year  Wins   Loss  Win%  Goal for  \\\n",
       "Boston Bruins               1990    44    24  0.550   299       264   \n",
       "Buffalo Sabres              1990    31    30  0.388   292       278   \n",
       "Calgary Flames              1990    46    26  0.575   344       263   \n",
       "Chicago Blackhawks          1990    49    23  0.613   284       211   \n",
       "Detroit Red Wings           1990    34    38  0.425   273       298   \n",
       "Edmonton Oilers             1990    37    37  0.463   272       272   \n",
       "Hartford Whalers            1990    31    38  0.388   238       276   \n",
       "Los Angeles Kings           1990    46    24  0.575   340       254   \n",
       "Minnesota North Stars       1990    27    39  0.338   256       266   \n",
       "Montreal Canadiens          1990    39    30  0.487   273       249   \n",
       "New Jersey Devils           1990    32    33  0.400   272       264   \n",
       "New York Islanders          1990    25    45  0.312   223       290   \n",
       "New York Rangers            1990    36    31  0.450   297       265   \n",
       "Philadelphia Flyers         1990    33    37  0.412   252       267   \n",
       "Pittsburgh Penguins         1990    41    33  0.512   342       305   \n",
       "Quebec Nordiques            1990    16    50  0.200   236       354   \n",
       "St. Louis Blues             1990    47    22  0.588   310       250   \n",
       "Toronto Maple Leafs         1990    23    46  0.287   241       318   \n",
       "Vancouver Canucks           1990    28    43  0.350   243       315   \n",
       "Washington Capitals         1990    37    36  0.463   258       258   \n",
       "Winnipeg Jets               1990    26    43  0.325   260       288   \n",
       "Boston Bruins               1991    36    32  0.450   270       275   \n",
       "Buffalo Sabres              1991    31    37  0.388   289       299   \n",
       "Calgary Flames              1991    31    37  0.388   296       305   \n",
       "Chicago Blackhawks          1991    36    29  0.450   257       236   \n",
       "\n",
       "                       Goal aganist  \n",
       "Boston Bruins                   NaN  \n",
       "Buffalo Sabres                  NaN  \n",
       "Calgary Flames                  NaN  \n",
       "Chicago Blackhawks              NaN  \n",
       "Detroit Red Wings               NaN  \n",
       "Edmonton Oilers                 NaN  \n",
       "Hartford Whalers                NaN  \n",
       "Los Angeles Kings               NaN  \n",
       "Minnesota North Stars           NaN  \n",
       "Montreal Canadiens              NaN  \n",
       "New Jersey Devils               NaN  \n",
       "New York Islanders              NaN  \n",
       "New York Rangers                NaN  \n",
       "Philadelphia Flyers             NaN  \n",
       "Pittsburgh Penguins             NaN  \n",
       "Quebec Nordiques                NaN  \n",
       "St. Louis Blues                 NaN  \n",
       "Toronto Maple Leafs             NaN  \n",
       "Vancouver Canucks               NaN  \n",
       "Washington Capitals             NaN  \n",
       "Winnipeg Jets                   NaN  \n",
       "Boston Bruins                   NaN  \n",
       "Buffalo Sabres                  NaN  \n",
       "Calgary Flames                  NaN  \n",
       "Chicago Blackhawks              NaN  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task5\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "res = requests.get(\"https://www.scrapethissite.com/pages/forms/?page_num=1\")\n",
    "res\n",
    "soup = BeautifulSoup(res.text,\"html.parser\")\n",
    "tr_tags = soup.find_all(\"tr\",{\"class\":\"team\"})\n",
    "\n",
    "'''\n",
    "team_name = tr_tags[0].find(\"td\",{\"class\":\"name\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\")\n",
    "year = tr_tags[0].find(\"td\",{\"class\":\"year\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\")\n",
    "wins = tr_tags[0].find(\"td\",{\"class\":\"wins\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\")\n",
    "loss = tr_tags[0].find(\"td\",{\"class\":\"losses\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\")\n",
    "win_percentage = tr_tags[0].find(\"td\",{\"class\":\"pct text-success\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\")\n",
    "goal_for = tr_tags[0].find(\"td\",{\"class\":\"gf\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\")\n",
    "goal_aganist = tr_tags[0].find(\"td\",{\"class\":\"ga\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\")'''\n",
    "\n",
    "team_name = []\n",
    "year = []\n",
    "wins = []\n",
    "loss = []\n",
    "win_percentage = []\n",
    "goal_for = []\n",
    "goal_aganist = []\n",
    "\n",
    "with open(\"game.csv\",mode=\"w\",encoding=\"utf-8\")as fd:\n",
    "    fd.write(\"Team name,Year,Wins,Loss,Win%,Goal for,Goal aganist\\n\")\n",
    "    for i in range(len(tr_tags)):\n",
    "        team_name.append(tr_tags[i].find(\"td\",{\"class\":\"name\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\"))\n",
    "        year.append(tr_tags[i].find(\"td\",{\"class\":\"year\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\"))\n",
    "        wins.append(tr_tags[i].find(\"td\",{\"class\":\"wins\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\"))\n",
    "        loss.append(tr_tags[i].find(\"td\",{\"class\":\"losses\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\"))\n",
    "        win_percentage .append(tr_tags[i].find_all(\"td\")[5].text.strip(\"\\n\").strip(\" \").strip(\"\\n\"))\n",
    "        goal_for.append(tr_tags[i].find(\"td\",{\"class\":\"gf\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\"))\n",
    "        goal_aganist.append(tr_tags[i].find(\"td\",{\"class\":\"ga\"}).text.strip(\"\\n\").strip(\" \").strip(\"\\n\"))\n",
    "        fd.write(f\"\\\"{team_name[i]}\\\",\\\"{year[i]}\\\",\\\"{wins[i]}\\\",\\\"{loss[i]}\\\",\\\"{win_percentage[i]}\\\",\\\"{ goal_for[i]}\\\",\\\"{ goal_aganist[i]}\\\",\\n\")\n",
    "game_df = pd.read_csv(\"game.csv\")        \n",
    "game_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Username</th>\n",
       "      <th>Email</th>\n",
       "      <th>Street</th>\n",
       "      <th>Suite</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip_code</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Leanne Graham</td>\n",
       "      <td>Bret</td>\n",
       "      <td>Sincere@april.biz</td>\n",
       "      <td>Kulas Light</td>\n",
       "      <td>Apt. 556</td>\n",
       "      <td>Gwenborough</td>\n",
       "      <td>92998-3874</td>\n",
       "      <td>-37.3159</td>\n",
       "      <td>81.1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ervin Howell</td>\n",
       "      <td>Antonette</td>\n",
       "      <td>Shanna@melissa.tv</td>\n",
       "      <td>Victor Plains</td>\n",
       "      <td>Suite 879</td>\n",
       "      <td>Wisokyburgh</td>\n",
       "      <td>90566-7771</td>\n",
       "      <td>-43.9509</td>\n",
       "      <td>-34.4618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Clementine Bauch</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Nathan@yesenia.net</td>\n",
       "      <td>Douglas Extension</td>\n",
       "      <td>Suite 847</td>\n",
       "      <td>McKenziehaven</td>\n",
       "      <td>59590-4157</td>\n",
       "      <td>-68.6102</td>\n",
       "      <td>-47.0653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Patricia Lebsack</td>\n",
       "      <td>Karianne</td>\n",
       "      <td>Julianne.OConner@kory.org</td>\n",
       "      <td>Hoeger Mall</td>\n",
       "      <td>Apt. 692</td>\n",
       "      <td>South Elvis</td>\n",
       "      <td>53919-4257</td>\n",
       "      <td>29.4572</td>\n",
       "      <td>-164.2990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chelsey Dietrich</td>\n",
       "      <td>Kamren</td>\n",
       "      <td>Lucio_Hettinger@annie.ca</td>\n",
       "      <td>Skiles Walks</td>\n",
       "      <td>Suite 351</td>\n",
       "      <td>Roscoeview</td>\n",
       "      <td>33263</td>\n",
       "      <td>-31.8129</td>\n",
       "      <td>62.5342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mrs. Dennis Schulist</td>\n",
       "      <td>Leopoldo_Corkery</td>\n",
       "      <td>Karley_Dach@jasper.info</td>\n",
       "      <td>Norberto Crossing</td>\n",
       "      <td>Apt. 950</td>\n",
       "      <td>South Christy</td>\n",
       "      <td>23505-1337</td>\n",
       "      <td>-71.4197</td>\n",
       "      <td>71.7478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Kurtis Weissnat</td>\n",
       "      <td>Elwyn.Skiles</td>\n",
       "      <td>Telly.Hoeger@billy.biz</td>\n",
       "      <td>Rex Trail</td>\n",
       "      <td>Suite 280</td>\n",
       "      <td>Howemouth</td>\n",
       "      <td>58804-1099</td>\n",
       "      <td>24.8918</td>\n",
       "      <td>21.8984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Nicholas Runolfsdottir V</td>\n",
       "      <td>Maxime_Nienow</td>\n",
       "      <td>Sherwood@rosamond.me</td>\n",
       "      <td>Ellsworth Summit</td>\n",
       "      <td>Suite 729</td>\n",
       "      <td>Aliyaview</td>\n",
       "      <td>45169</td>\n",
       "      <td>-14.3990</td>\n",
       "      <td>-120.7677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Glenna Reichert</td>\n",
       "      <td>Delphine</td>\n",
       "      <td>Chaim_McDermott@dana.io</td>\n",
       "      <td>Dayna Park</td>\n",
       "      <td>Suite 449</td>\n",
       "      <td>Bartholomebury</td>\n",
       "      <td>76495-3109</td>\n",
       "      <td>24.6463</td>\n",
       "      <td>-168.8889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Clementina DuBuque</td>\n",
       "      <td>Moriah.Stanton</td>\n",
       "      <td>Rey.Padberg@karina.biz</td>\n",
       "      <td>Kattie Turnpike</td>\n",
       "      <td>Suite 198</td>\n",
       "      <td>Lebsackbury</td>\n",
       "      <td>31428-2261</td>\n",
       "      <td>-38.2386</td>\n",
       "      <td>57.2232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      Name          Username                      Email  \\\n",
       "0   1             Leanne Graham              Bret          Sincere@april.biz   \n",
       "1   2              Ervin Howell         Antonette          Shanna@melissa.tv   \n",
       "2   3          Clementine Bauch          Samantha         Nathan@yesenia.net   \n",
       "3   4          Patricia Lebsack          Karianne  Julianne.OConner@kory.org   \n",
       "4   5          Chelsey Dietrich            Kamren   Lucio_Hettinger@annie.ca   \n",
       "5   6      Mrs. Dennis Schulist  Leopoldo_Corkery    Karley_Dach@jasper.info   \n",
       "6   7           Kurtis Weissnat      Elwyn.Skiles     Telly.Hoeger@billy.biz   \n",
       "7   8  Nicholas Runolfsdottir V     Maxime_Nienow       Sherwood@rosamond.me   \n",
       "8   9           Glenna Reichert          Delphine    Chaim_McDermott@dana.io   \n",
       "9  10        Clementina DuBuque    Moriah.Stanton     Rey.Padberg@karina.biz   \n",
       "\n",
       "              Street      Suite            City    Zip_code      Lat       Lng  \n",
       "0        Kulas Light   Apt. 556     Gwenborough  92998-3874 -37.3159   81.1496  \n",
       "1      Victor Plains  Suite 879     Wisokyburgh  90566-7771 -43.9509  -34.4618  \n",
       "2  Douglas Extension  Suite 847   McKenziehaven  59590-4157 -68.6102  -47.0653  \n",
       "3        Hoeger Mall   Apt. 692     South Elvis  53919-4257  29.4572 -164.2990  \n",
       "4       Skiles Walks  Suite 351      Roscoeview       33263 -31.8129   62.5342  \n",
       "5  Norberto Crossing   Apt. 950   South Christy  23505-1337 -71.4197   71.7478  \n",
       "6          Rex Trail  Suite 280       Howemouth  58804-1099  24.8918   21.8984  \n",
       "7   Ellsworth Summit  Suite 729       Aliyaview       45169 -14.3990 -120.7677  \n",
       "8         Dayna Park  Suite 449  Bartholomebury  76495-3109  24.6463 -168.8889  \n",
       "9    Kattie Turnpike  Suite 198     Lebsackbury  31428-2261 -38.2386   57.2232  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Task6\n",
    "import requests\n",
    "import pandas as pd\n",
    "res = requests.get(\"https://jsonplaceholder.typicode.com/users\")\n",
    "my_data = res.json()\n",
    "'''\n",
    "name = my_data[0][\"name\"]\n",
    "username = my_data[0][\"username\"]\n",
    "email = my_data[0][\"email\"]\n",
    "street = my_data[0][\"address\"][\"street\"]\n",
    "suite = my_data[0][\"address\"][\"suite\"]\n",
    "city = my_data[0][\"address\"][\"city\"]\n",
    "zip_code = my_data[0][\"address\"][\"zipcode\"]\n",
    "lat = my_data[0][\"address\"][\"geo\"][\"lat\"]\n",
    "lng = my_data[0][\"address\"][\"geo\"][\"lng\"]\n",
    "len(my_data)'''\n",
    "name = []\n",
    "username = []\n",
    "email = []\n",
    "street = []\n",
    "suite = []\n",
    "city = []\n",
    "zip_code = []\n",
    "lat  = []\n",
    "lng = []\n",
    "with open(\"user_data.csv\",mode=\"w\",encoding=\"utf-8\") as fd:\n",
    "    fd.write(\"id,Name,Username,Email,Street,Suite,City,Zip_code,Lat,Lng\\n\")\n",
    "    for i in range(len(my_data)):\n",
    "        name.append(my_data[i][\"name\"])\n",
    "        username.append(my_data[i][\"username\"])   \n",
    "        email.append(my_data[i][\"email\"])\n",
    "        street.append(my_data[i][\"address\"][\"street\"])\n",
    "        suite.append(my_data[i][\"address\"][\"suite\"])\n",
    "        city.append(my_data[i][\"address\"][\"city\"])\n",
    "        zip_code.append(my_data[i][\"address\"][\"zipcode\"])\n",
    "        lat.append(my_data[i][\"address\"][\"geo\"][\"lat\"])\n",
    "        lng.append(my_data[i][\"address\"][\"geo\"][\"lng\"])\n",
    "        fd.write(f\"{i+1},\\\"{name[i]}\\\",\\\"{username[i]}\\\",\\\"{email[i]}\\\",\\\"{street[i]}\\\",\\\"{suite[i]}\\\",\\\"{city[i]}\\\",\\\"{zip_code[i]}\\\",\\\"{lat[i]}\\\",\\\"{lng[i]}\\\"\\n\")\n",
    "\n",
    "\n",
    "data={\"name\":name,\"username\":username,\"email\":email,\"street\":street,\"suit\":suite,\"city\":city,\"zip code\":zip_code,\"lat\":lat,\"lng\":lng}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel(\"country.xlsx\", index=False)\n",
    "\n",
    "user_df = pd.read_csv(\"user_data.csv\")    \n",
    "user_df    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "github link\n",
    "https://github.com/doaa-shabrawy/scraping-cont.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
